# Fiery: RVM for Korea: KHU Data Capstone Design Project

---

This repository is for Data Analysis Capstone Design Project

<img src="./docs/RVM_flow.png" width="500" height="500"/>

---

## Problem Definition

Since high-quality PET (PolyEthylene Terephtalate) recycled materials can be obtained from clear plastic bottles, Korea's recyclable material separation collection regulations, in this case regarding the collection of clear plastic bottles (or PET bottles), require that clear plastic bottles be separated from colored bottles and other plastics, and that they be disposed of with external and internal debris such as plastic labels, liquids, and residue removed.

One of the factors that hinders the recycling process in the existing system is the lack of personal control over recycling, as individuals do not strongly feel the need to recycle plastic bottles in the socially correct method.

This creates the need for an additional separation phase to separate other substances/materials that are mixed with the clear plastic bottle load. This leads to a waste of resources, money, and time. To solve these problems, this study aims to improve the PET bottle separation collection system by utilizing artificial intelligence technology and implementing an RVM system for domestic adoption.

---

## Approach, Experiment Result

### Classification Model

- ResNet-50
- EfficientNet b4

<table>
  <tr>
    <td><a href="link"><img src="./docs/ResNet_precision.png" width="300"></a></td>
    <td><a href="link"><img src="./docs/ResNet_recall.png" width="300"></a></td>
  </tr>
</table>

<br />

<table>
  <tr>
    <td><a href="link"><img src="./docs/EfficientNet_train_precision.png" width="300"></a></td>
    <td><a href="link"><img src="./docs/EfficientNet_train_recall.png" width="300"></a></td>
  </tr>
</table>

### Anomaly Dection

- Light U-Net

<table>
  <tr>
    <td><a href="link"><img src="./docs/Unet_train_psnr.png" width="300"></a></td>
    <td><a href="link"><img src="./docs/Unet_train_ssim.png" width="300"></a></td>
  </tr>
</table>

### Physical devices

- Arduino Electronic Scale
<figure class="half">  
<a href="link"><img src="./docs/RVM_scenario.png"></a>  
<a href="link"><img src="./docs/Arduino_weight.png"></a>  
</figure>
  <br />

Combining classification models(with Data Augmentation), outlier detection models(for clear Pet Detection), and Arduino scales

---

## Conclusion

**1. Purpose**

- Design and implementation of an RVM system that complies with domestic separate collection regulations
- Pursuit of accuracy and performance through a combination of artificial intelligence model and physical device

**2. Experiments**

- Performance verification of classification model and encoder-decoder model
- Improving efficiency and saving resources by using Arduino digital scales

**3. Results**

- EfficientNet performed better than ResNet
- The enhancement technique needs to be adjusted for the most effective details due to the dataset characteristics of ColorJitter
- U-Net needs further experimentation with practical coupling to RVM systems

---

## Project Structure

The directory structure: pytorch lightning hydra template from https://github.com/ashleve/lightning-hydra-template

```
â”œâ”€â”€ .github                   <- Github Actions workflows
|
â”œâ”€â”€ cam                       <- web cam, Flask, Arduino
â”‚
â”œâ”€â”€ configs                   <- Hydra configs
â”‚   â”œâ”€â”€ callbacks                <- Callbacks configs
â”‚   â”œâ”€â”€ data                     <- Data configs
â”‚   â”œâ”€â”€ debug                    <- Debugging configs
â”‚   â”œâ”€â”€ experiment               <- Experiment configs
â”‚   â”œâ”€â”€ extras                   <- Extra utilities configs
â”‚   â”œâ”€â”€ hparams_search           <- Hyperparameter search configs
â”‚   â”œâ”€â”€ hydra                    <- Hydra configs
â”‚   â”œâ”€â”€ local                    <- Local configs
â”‚   â”œâ”€â”€ logger                   <- Logger configs
â”‚   â”œâ”€â”€ model                    <- Model configs
â”‚   â”œâ”€â”€ paths                    <- Project paths configs
â”‚   â”œâ”€â”€ trainer                  <- Trainer configs
â”‚   â”‚
â”‚   â”œâ”€â”€ eval.yaml             <- Main config for evaluation
â”‚   â””â”€â”€ train.yaml            <- Main config for training
â”‚
â”œâ”€â”€ data                   <- Project data
â”‚
â”œâ”€â”€ logs                   <- Logs generated by hydra and lightning loggers
â”‚
â”œâ”€â”€ notebooks              <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                             the creator's initials, and a short `-` delimited description,
â”‚                             e.g. `1.0-jqp-initial-data-exploration.ipynb`.
â”‚
â”œâ”€â”€ scripts                <- Shell scripts
â”‚
â”œâ”€â”€ src                    <- Source code
â”‚   â”œâ”€â”€ data                     <- Data scripts
â”‚   â”œâ”€â”€ models                   <- Model scripts
â”‚   â”œâ”€â”€ utils                    <- Utility scripts
â”‚   â”‚
â”‚   â”œâ”€â”€ eval.py                  <- Run evaluation
â”‚   â””â”€â”€ train.py                 <- Run training
â”‚
â”œâ”€â”€ tests                  <- Tests of any kind
â”‚
â”œâ”€â”€ .env.example              <- Example of file for storing private environment variables
â”œâ”€â”€ .gitignore                <- List of files ignored by git
â”œâ”€â”€ .pre-commit-config.yaml   <- Configuration of pre-commit hooks for code formatting
â”œâ”€â”€ .project-root             <- File for inferring the position of project root directory
â”œâ”€â”€ environment.yaml          <- File for installing conda environment
â”œâ”€â”€ Makefile                  <- Makefile with commands like `make train` or `make test`
â”œâ”€â”€ pyproject.toml            <- Configuration options for testing and linting
â”œâ”€â”€ requirements.txt          <- File for installing python dependencies
â”œâ”€â”€ setup.py                  <- File for installing project as a package
â””â”€â”€ README.md
```

<br>

## ðŸš€Â Â Quickstart

```bash
# clone project
git clone https://github.com/muk-jjang/2024_DataCapstone_Recycling_Fiery.git

# [OPTIONAL] create conda environment
conda create -n myenv python=3.9
conda activate myenv

# install requirements
pip install -r requirements.txt
```
